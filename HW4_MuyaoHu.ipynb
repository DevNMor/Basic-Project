{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2c84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306c5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================\n",
      "\n",
      "Test Q1\n",
      "  Symbol                Name Last Price   Change % Change    Volume Market Cap\n",
      "0   STNE        StoneCo Ltd.      13.57    +3.97  +41.26%   43.307M     4.534B\n",
      "1    GME      GameStop Corp.      89.82    +2.12   +2.42%    4.849M     7.248B\n",
      "2   NVDA  NVIDIA Corporation     259.93   +12.27   +4.95%   36.552M   647.746B\n",
      "3   DIDI    DiDi Global Inc.     3.8589  +1.2989  +50.74%  156.157M    18.244B\n",
      "4    FDX   FedEx Corporation     215.76   -12.22   -5.36%    5.036M     57.17B\n",
      "5    PIK        Kidpik Corp.       7.19    +2.44  +51.30%   83.298M    54.746M\n",
      "\n",
      "==================\n",
      "\n",
      "Test Q2.1 - Try different parameter values to make sure all options work\n",
      "\n",
      "1.lemmatized=True, remove_stopword=True\n",
      " ['practice', 'thing', 'washing', 'hand', 'soap', 'water', 'least', '20', 'second', 'avoid', 'people', 'sick', 'cleaning', 'disinfect', 'high', 'touch', 'surface', 'household', 'common', 'area', 'e.g', 'table', 'chair', 'doorknob', 'etc', 'launder', 'item', 'like', 'plush', 'toy']\n",
      "\n",
      "2.lemmatized=False, remove_stopword=True\n",
      " ['practice', 'things', 'washing', 'hands', 'soap', 'water', 'least', '20', 'seconds', 'avoiding', 'people', 'sick', 'cleaning', 'disinfecting', 'high', 'touch', 'surfaces', 'household', 'common', 'areas', 'e.g', 'tables', 'chairs', 'doorknobs', 'etc', 'laundering', 'items', 'like', 'plush', 'toys']\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False\n",
      " ['by', 'having', 'them', 'practice', 'the', 'same', 'things', 'you', 'have', 'to', 'do', 'washing', 'hands', 'with', 'soap', 'and', 'water', 'for', 'at', 'least', '20', 'seconds', 'avoiding', 'people', 'who', 'are', 'sick', 'cleaning', 'and', 'disinfecting', 'high', 'touch', 'surfaces', 'in', 'household', 'common', 'areas', 'e.g', 'tables', 'chairs', 'doorknobs', 'etc', 'and', 'laundering', 'items', 'like', 'plush', 'toys']\n",
      "\n",
      "==================\n",
      "\n",
      "Test Q2.2\n",
      "1.lemmatized=True, remove_stopword=True\n",
      " (92, 1044)\n",
      "\n",
      "2.lemmatized=False, remove_stopword=True\n",
      " (92, 1205)\n",
      "\n",
      "3.lemmatized=False, remove_stopword=False\n",
      " (92, 1302)\n",
      "\n",
      "==================\n",
      "\n",
      "Test Q2.3 \n",
      "0: Can I get COVID-19 from animals when travelling to other countries?\n",
      "\n",
      "Top 3 answers:\n",
      "\n",
      "0: Although the current spread and growth of the COVID-19 outbreak is primarily associated with spread from person to person, experts agree that the virus likely originated from bats and may have passed through an intermediary animal source (currently unknown) in China before being transmitted to humans.  It is recommended that individuals who travel to avoid contact with animals, including wild meat and wet (live animal) markets.  If you are considering travel, check the latest travel health notices for the most up-to-date travel advice prior to travelling.  Importers, rescue organizations and adoptive families should limit or postpone importing animals from affected areas. If animals are imported from an affected area: they should be closely monitored for signs of illness, you should contact a veterinarian if they become sick, and call ahead to ensure they are aware of the circumstances\n",
      "\n",
      "2: There is currently no evidence to suggest that this virus is circulating in animals in Canada.  It is possible that some types of animals can be infected with COVID-19 but there is no evidence that pets or other animals can spread the virus. There are still many unknowns about COVID-19 and this is an area that remains to be studied and understood.  Until we know more, if you have been diagnosed with COVID-19 and have a pet or other animal: avoid close contact with them, do not snuggle or kiss them, or let them lick you, sit on your lap, or sleep in your bed, practice good cough etiquette, avoid coughing and sneezing on your animals, have another member of your household care for your animals (if this is not possible, always wash your hands before touching or feeding them), and limit your animal's contact with other people and animals (this may mean keeping them indoors)  To date, there have not been any reports of livestock being infected by COVID-19 anywhere. However, livestock producers should follow normal biosecurity measures as always. This includes limiting visitors or workers who may have travelled to, or been in contact with, someone from an affected area.\n",
      "\n",
      "81: While this virus did emerge from an animal source, it is only passing person-to-person currently. Currently, there is no evidence that shows a pet can become sick with COVID-19... but animals can spread disease to people, and people can spread disease to animals. So it is important to always wash your hands before and after interacting with animals.\n",
      "\n",
      "\n",
      "==================\n",
      "\n",
      "Test Q2.4\n",
      "Top-1: 0.3261\n",
      "Top-3: 0.5870\n",
      "Top-5: 0.6522\n",
      "\n",
      "==================\n",
      "\n",
      "Test Q2.6\n",
      "doc1:\n",
      " {91: 0.25, 46: 0.25, 65: 0.25, 80: 0.25, 48: 0.25}\n",
      "doc2:\n",
      " {46: 0.25, 42: 0.1875, 72: 0.1875, 20: 0.1875, 68: 0.125}\n",
      "best answers for doc1:\n",
      " There are many types of coronaviruses. Some only cause illness in people, and some only infect animals. COVID-19 is likely due to an animal coronavirus being able to infect and spread among people. In the past, there was Middle East Respiratory Syndrom (MERS) and Severe Acute Respiratory (SARS) which are both coronaviruses that came from animals and spread among people.   [[Would you like more information on MERs?]] MERs is Middle East Respiratory Syndrome. It is also caused by coronavirus, similar to COVID-19. This virus was first reported in 2012 in Saudi Arabia. Their symptoms are severe acute respiratory illness which includes fever, cough, and shortness of breath. The virus does not pass easily person-to-person unless there is close contact, which includes providing unprotected care to a patient.  [[Would you like more information?]] SARS is Severe Acute Respiratory Syndrome. It was identified in 2003. It is thought to be an animal virus, though the animal source has not yet been identified. It transmits person-to-person, and has influenza-like symptoms, which include fever, malaise, headaches, diarrhea, and shivering. Currently, SARS-CoV is not being transmitted anywhere in the world. Since the 2003 epidemic, it has appeared four times due to laboratory accidents. \n",
      "\n",
      "best answers for doc2:\n",
      " SARS-CoV-2 means Severe Acute Respiratory Syndrome Coronavirus 2. It is the virus that leads to the coronavirus disease, also known as COVID-19. Unlike SARS, in COVID19 patients become highly infectious before they become seriously ill, explaining at least in part why Covid-19 acts like a super-SARS.  [[Would you like to know why there are two names for COVID19 (i.e. SARS-CoV-2 and COVID19)?]] [[What is the difference between SARS-CoV-2 and COVID19?]] SARS-CoV-2 refers to the virus that causes COVID-19. COVID-19 is the disease itself. The virus has a different name for the disease to support the development of diagnostic testing, vaccines, and medicines. The disease is named as such to enable discussion on disease prevention, spread, its ability to transmit, its severity, and its treatment. \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test Q1\n",
    "    \n",
    "    def extract(text):\n",
    "\n",
    "        data = None\n",
    "\n",
    "        total = re.split(r'\t', text)\n",
    "        total = total[:-1]\n",
    "        symb0 = total[::8]\n",
    "        symb = tuple(i.replace('\\n', '') if '\\n' in i else i for i in symb0)\n",
    "        name = tuple(total[1::8])\n",
    "        price = tuple(total[2::8])\n",
    "        change = tuple(total[4::8])\n",
    "        per_change = tuple(total[5::8])\n",
    "        vol = tuple(total[6::8])\n",
    "        cap = tuple(total[7::8])\n",
    "        data = pd.DataFrame([symb, name, price, change, per_change, vol, cap], \\\n",
    "                 index = ['Symbol', 'Name', 'Last Price', 'Change', '% Change', 'Volume', 'Market Cap']).T\n",
    "\n",
    "        return data\n",
    "\n",
    "    \n",
    "    text='''STNE\tStoneCo Ltd.\t13.57\t12:04PM EDT\t+3.97\t+41.26%\t43.307M\t4.534B\t\n",
    "GME\tGameStop Corp.\t89.82\t12:04PM EDT\t+2.12\t+2.42%\t4.849M\t7.248B\t\n",
    "NVDA\tNVIDIA Corporation\t259.93\t12:04PM EDT\t+12.27\t+4.95%\t36.552M\t647.746B\t\n",
    "DIDI\tDiDi Global Inc.\t3.8589\t12:04PM EDT\t+1.2989\t+50.74%\t156.157M\t18.244B\t\n",
    "FDX\tFedEx Corporation\t215.76\t12:04PM EDT\t-12.22\t-5.36%\t5.036M\t57.17B\t\n",
    "PIK\tKidpik Corp.\t7.19\t12:04PM EDT\t+2.44\t+51.30%\t83.298M\t54.746M\t'''\n",
    "\n",
    "    \n",
    "    print(\"\\n==================\\n\")\n",
    "    print(\"Test Q1\")\n",
    "    print(extract(text))\n",
    "    \n",
    "    def tokenize(doc, lemmatized=True, remove_stopword=True):\n",
    "\n",
    "        tokens =[]\n",
    "\n",
    "        def pos(x):\n",
    "            if x.startswith('J'):\n",
    "                return 'a'\n",
    "            elif x.startswith('V'):\n",
    "                return 'v'\n",
    "            elif x.startswith('N'):\n",
    "                return 'n'\n",
    "            elif x.startswith('R'):\n",
    "                return 'r'\n",
    "            else:\n",
    "                return 'n'\n",
    "\n",
    "        tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "        if lemmatized == True:\n",
    "            pos_list = nltk.pos_tag(tokens)\n",
    "            tokens = list(map(lambda x: WordNetLemmatizer().lemmatize(x[0], pos(x[1])), pos_list))\n",
    "\n",
    "        if remove_stopword == True:\n",
    "            stop_words = stopwords.words('english')\n",
    "            tokens = list(i for i in tokens if i.lower() not in stop_words)\n",
    "\n",
    "        tokens = list(map(lambda x: x.lower(), tokens))\n",
    "        tokens=[i.strip(string.punctuation) for i in tokens if i.strip(string.punctuation)!='']\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "    def compute_tfidf(docs, lemmatized=True, remove_stopword=True):\n",
    "    \n",
    "        smoothed_tf_idf = None\n",
    "\n",
    "        docs_dic = {idx: nltk.FreqDist(tokenize(doc, lemmatized, remove_stopword)) for idx, doc in enumerate(docs)}\n",
    "        docs_freq = pd.DataFrame.from_dict(docs_dic).T.fillna(0)\n",
    "        doc_len = docs_freq.values.sum(axis=1)\n",
    "        tf=np.divide(docs_freq.values, doc_len[:,None])\n",
    "        df = np.where(tf>0,1,0)\n",
    "        idf = np.log(np.divide(len(docs)+1, np.sum(df, axis=0)+1))+1\n",
    "        smoothed_tf_idf = normalize(tf*idf)\n",
    "\n",
    "        return smoothed_tf_idf\n",
    "\n",
    "    def Match(questions, answers, lemmatized = True, remove_stopword = True, top_K = 3):\n",
    "\n",
    "        result = []\n",
    "\n",
    "        total = questions + answers\n",
    "        total_tfidf = compute_tfidf(total, lemmatized, remove_stopword)\n",
    "        A_tfidf = total_tfidf[len(questions):(len(questions)+len(answers))]\n",
    "\n",
    "        for i in range(len(questions)):\n",
    "            q_tfidf = total_tfidf[i]\n",
    "            q_A = np.row_stack((q_tfidf, A_tfidf))\n",
    "            similarity=1-pairwise_distances(q_A, metric = 'cosine')\n",
    "            result.append(similarity[0].argsort()[::-1][1:top_K+1]-1)\n",
    "\n",
    "        return result  \n",
    "\n",
    "    def calculate_hit_rate(question, answer, found_answers):\n",
    "\n",
    "        hit_rate = None\n",
    "\n",
    "        success = []\n",
    "        for i in range(len(question)):\n",
    "            if answer[answer.qid == i].index[0] in found_answers[i]:\n",
    "                success.append(1)\n",
    "            else:\n",
    "                success.append(0)\n",
    "\n",
    "        hit_rate = np.mean(success)\n",
    "\n",
    "        return hit_rate\n",
    "    \n",
    "    question = pd.read_csv(\"hw4_question.csv\")\n",
    "    answer = pd.read_csv(\"hw4_answer.csv\")\n",
    "    \n",
    "    print(\"\\n==================\\n\")\n",
    "    print(\"Test Q2.1 - Try different parameter values to make sure all options work\\n\")\n",
    "    \n",
    "    print(\"1.lemmatized=True, remove_stopword=True\\n\", tokenize(answer[\"answer\"].loc[0], lemmatized=True, remove_stopword=True))\n",
    "\n",
    "    print(\"\\n2.lemmatized=False, remove_stopword=True\\n\",tokenize(answer[\"answer\"].loc[0], lemmatized=False, remove_stopword=True))\n",
    "\n",
    "    print(\"\\n3.lemmatized=False, remove_stopword=False\\n\",tokenize(answer[\"answer\"].loc[0], lemmatized=False, remove_stopword=False))\n",
    "       \n",
    "    print(\"\\n==================\\n\")\n",
    "    print(\"Test Q2.2\")\n",
    "    print(\"1.lemmatized=True, remove_stopword=True\\n\", compute_tfidf(answer[\"answer\"], lemmatized=True, remove_stopword=True).shape)\n",
    "\n",
    "    print(\"\\n2.lemmatized=False, remove_stopword=True\\n\",compute_tfidf(answer[\"answer\"], lemmatized=False, remove_stopword=True).shape)\n",
    "\n",
    "    print(\"\\n3.lemmatized=False, remove_stopword=False\\n\",compute_tfidf(answer[\"answer\"], lemmatized=False, remove_stopword=False).shape)\n",
    "    \n",
    "    print(\"\\n==================\\n\")\n",
    "    print(\"Test Q2.3 \")\n",
    "    \n",
    "    top_index = Match(question.question.tolist(), answer.answer.tolist(), \\\n",
    "                  lemmatized = True, remove_stopword = True, top_K = 3)\n",
    "\n",
    "    print(f\"{question.iloc[0].qid}: {question.iloc[0].question}\")\n",
    "    print(f\"\\nTop 3 answers:\\n\")\n",
    "    for i in top_index[0]:\n",
    "        print(f'{answer.iloc[i][\"qid\"]}: {answer.iloc[i][\"answer\"]}\\n')\n",
    "\n",
    "    \n",
    "    print(\"\\n==================\\n\")\n",
    "    print(\"Test Q2.4\")\n",
    "    for k in [1, 3, 5]:\n",
    "        top_index = Match(question.question.tolist(), answer.answer.tolist(), \\\n",
    "                      lemmatized = True, remove_stopword = True, top_K = k)\n",
    "\n",
    "        hr = calculate_hit_rate(question, answer, top_index)\n",
    "        print(f\"Top-{k}: {hr:.4f}\")\n",
    "        \n",
    "    print(\"\\n==================\\n\")\n",
    "    print(\"Test Q2.6\")\n",
    "    \n",
    "    ## Since we cannot calculate the tf-idf of the new questions to get their similarities with answers we have\n",
    "    ## we shall manually get the feature words that can representate the whole question\n",
    "\n",
    "    def customize_stopwords(docs, stop_words_number, lemmatized=True, remove_stopword=True):\n",
    "\n",
    "        docs_dic = {idx: nltk.FreqDist(tokenize(doc, lemmatized, remove_stopword)) for idx, doc in enumerate(docs)}\n",
    "        docs_freq = pd.DataFrame.from_dict(docs_dic).T.fillna(0)\n",
    "        doc_len = docs_freq.values.sum(axis=1)\n",
    "        tf=np.divide(docs_freq.values, doc_len[:,None])\n",
    "        df = np.where(tf>0,1,0)\n",
    "        idf = np.log(np.divide(len(docs)+1, np.sum(df, axis=0)+1))+1\n",
    "        stop_words = list(map(lambda i: docs_freq.columns[i], idf.argsort()[0:stop_words_number]))\n",
    "\n",
    "        return stop_words      \n",
    "\n",
    "    ## Next we design a new function, matching the tokens in the new question to tokens in the answers\n",
    "    ## The index of the best answer(s) along with the corresponding matching degree will be returned\n",
    "    ## If the tokens of a question are [a, b, c], and an answer's tokens only include [a, b] \n",
    "    ## then the matching degree would be 2/3\n",
    "\n",
    "    def Match_new(new_question, stop_words_number, match_number, questions, answers, lemmatized = True, remove_stopword = True):\n",
    "\n",
    "        total = questions + answers\n",
    "        new_stop = customize_stopwords(total, stop_words_number, lemmatized, remove_stopword)\n",
    "        new_Q = tokenize(new_question, lemmatized, remove_stopword)\n",
    "        keywords_Q = [i for i in new_Q if i not in new_stop]\n",
    "\n",
    "        list_answers = [tokenize(answer, lemmatized, remove_stopword) for answer in answers]\n",
    "        match_score = np.array(list(map(lambda x: np.sum([1 if i in x else 0 for i in keywords_Q]), list_answers)))\n",
    "        matching_index = match_score.argsort()[::-1][0:match_number]\n",
    "        matching_degree = np.divide(match_score, len(keywords_Q))\n",
    "        result = {idx: np.divide(match_score, len(keywords_Q))[idx] for idx in matching_index}\n",
    "\n",
    "        return result \n",
    "\n",
    "    ## Test our function\n",
    "\n",
    "    doc1 = 'What is multisystem inflammatory syndrome associated with COVID-19?'\n",
    "    doc2 = '''When administering a third dose of an mRNA vaccine to \n",
    "              eligible individuals as part of the primary series, should \n",
    "              the same vaccine type as the initial two doses be used?'''\n",
    "\n",
    "    questions = question.question.tolist()\n",
    "    answers = answer.answer.tolist()\n",
    "\n",
    "    print('doc1:\\n', Match_new(doc1, 10, 5, questions, answers, lemmatized = True, remove_stopword = True))\n",
    "    print('doc2:\\n', Match_new(doc2, 10, 5, questions, answers, lemmatized = True, remove_stopword = True))\n",
    "\n",
    "    ## As seen, the performance of the QA systme is pretty awful\n",
    "    ## that's because we've abandoned the use of cosine similarity, developing the system in a non-mathmatical way\n",
    "\n",
    "    print('best answers for doc1:\\n', answers[91], '\\n')\n",
    "    print('best answers for doc2:\\n', answers[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a843cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
